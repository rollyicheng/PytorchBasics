{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRUxPkMB5WDG"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FVgZHVg5WDI"
      },
      "source": [
        "**Learn the Basics** \\|\\| [Quickstart](quickstart_tutorial.html) \\|\\|\n",
        "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Learn the Basics\n",
        "================\n",
        "\n",
        "Authors: [Suraj Subramanian](https://github.com/subramen), [Seth\n",
        "Juarez](https://github.com/sethjuarez/), [Cassie\n",
        "Breviu](https://github.com/cassiebreviu/), [Dmitry\n",
        "Soshnikov](https://soshnikov.com/), [Ari\n",
        "Bornstein](https://github.com/aribornstein/)\n",
        "\n",
        "Most machine learning workflows involve working with data, creating\n",
        "models, optimizing model parameters, and saving the trained models. This\n",
        "tutorial introduces you to a complete ML workflow implemented in\n",
        "PyTorch, with links to learn more about each of these concepts.\n",
        "\n",
        "We\\'ll use the FashionMNIST dataset to train a neural network that\n",
        "predicts if an input image belongs to one of the following classes:\n",
        "T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker,\n",
        "Bag, or Ankle boot.\n",
        "\n",
        "[This tutorial assumes a basic familiarity with Python and Deep Learning\n",
        "concepts.]{.title-ref}\n",
        "\n",
        "Running the Tutorial Code\n",
        "-------------------------\n",
        "\n",
        "You can run this tutorial in a couple of ways:\n",
        "\n",
        "-   **In the cloud**: This is the easiest way to get started! Each\n",
        "    section has a \\\"Run in Microsoft Learn\\\" and \\\"Run in Google Colab\\\"\n",
        "    link at the top, which opens an integrated notebook in Microsoft\n",
        "    Learn or Google Colab, respectively, with the code in a fully-hosted\n",
        "    environment.\n",
        "-   **Locally**: This option requires you to setup PyTorch and\n",
        "    TorchVision first on your local machine ([installation\n",
        "    instructions](https://pytorch.org/get-started/locally/)). Download\n",
        "    the notebook or copy the code into your favorite IDE.\n",
        "\n",
        "How to Use this Guide\n",
        "---------------------\n",
        "\n",
        "If you\\'re familiar with other deep learning frameworks, check out the\n",
        "[0. Quickstart](quickstart_tutorial.html) first to quickly familiarize\n",
        "yourself with PyTorch\\'s API.\n",
        "\n",
        "If you\\'re new to deep learning frameworks, head right into the first\n",
        "section of our step-by-step guide: [1. Tensors](tensorqs_tutorial.html).\n",
        "\n",
        "::: {.toctree maxdepth=\"2\" hidden=\"\"}\n",
        "quickstart\\_tutorial tensorqs\\_tutorial data\\_tutorial\n",
        "transforms\\_tutorial buildmodel\\_tutorial autogradqs\\_tutorial\n",
        "optimization\\_tutorial saveloadrun\\_tutorial\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "j_T1rD6Y6Jim"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize Tensor\n",
        "#1.directly form data\n",
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "OA-JiIMN5xkq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.from a numpy array\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "xf3neVzs6Qw2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.from another tensor\n",
        "x_ones = torch.ones_like(x_data) #retain properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) #overrides the datatype of x_data, new tensor retinas properties(shape,dtype) of the arg tensor unless explicitly overridden\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "id": "J6xH558a6ceH",
        "outputId": "d830df8c-0424-4d8b-ddcc-02b811ad3b33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.9703, 0.8365],\n",
            "        [0.5035, 0.2330]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shape is a tuple of tensor dimensions, determines the dimensionality of output tensor\n",
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")"
      ],
      "metadata": {
        "id": "SeHGddp_73vP",
        "outputId": "c0d7b8be-fd55-4d8f-e5c5-9583c244ff69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.0209, 0.5381, 0.3579],\n",
            "        [0.2150, 0.0971, 0.5647]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor attributes: describe shape,dtype and device on which they stored\n",
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatypr of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "id": "QTzi1tpv-MA9",
        "outputId": "3a22086d-0dbf-4e29-afc5-6b583d76ac29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatypr of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor operations\n",
        "#operations can be run on CPU and Accelerator such as CUDA\n",
        "#using Colab, allocate an accelerator by runtime>change runtime type>gpu\n",
        "#move tensor to current accelerator if avail\n",
        "if torch.accelerator.is_available():\n",
        "  tensor = tensor.to(torch.accerlerator.current_accelerator())"
      ],
      "metadata": {
        "id": "0cCYSPSF-1vf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#numpy0like indexing slicing\n",
        "tensor = torch.ones(4,4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\") #:colon is a slice notation\n",
        "print(f\"Last column: {tensor[..., -1]}\")#...ellipsis are placeholder for full slices:\n",
        "tensor[:, 1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "e9Gly2XnADPR",
        "outputId": "fd4e8914-7bda-440f-9c20-da9c21dbf261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#joining tensors\n",
        "#torch.cat to concat tensors along a given dim\n",
        "#see also torch.stack\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim= 1)\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "NnjFV3DfDQOX",
        "outputId": "9958f24c-2e47-4e93-be55-2c6a3756361b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#arithmetic operation\n"
      ],
      "metadata": {
        "id": "bWVGnk0dDoAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}